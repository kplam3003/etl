import os
import sys

DATABASE_URI = os.environ.get('DATABASE_URI')
CRAWLER_DATABASE_URI = os.environ.get('CRAWLER_DATABASE_URI', DATABASE_URI)

GCP_PROJECT = os.environ.get('GCP_PROJECT')
GCP_ZONE = os.environ.get('GCP_ZONE')
GCP_MACHINE_IMAGE = os.environ.get('GCP_MACHINE_IMAGE')
GCP_STORAGE_BUCKET = os.environ.get('GCP_STORAGE_BUCKET')
GCP_DB_INSTANCE = os.environ.get('GCP_DB_INSTANCE')
GCP_PUBSUB_CRAWL_TOPIC_ID = os.environ.get('GCP_PUBSUB_CRAWL_TOPIC_ID')

MAX_VM = int(os.environ.get('MAX_VM', '3'))
SLEEP = int(os.environ.get('SLEEP', '30'))
ROWS_PER_STEP = int(os.environ.get('ROWS_PER_STEP', '200'))

WEB_WRAPPER_URL = os.environ.get('WEB_WRAPPER_URL', 'http://34.121.81.95')

# Logging
LOGGER_NAME = os.environ.get('LOGGER_NAME', 'dev-etl-master')
LOGGER = "application"

# PubSub Topic
GCP_PUBSUB_TOPIC_AFTER_TASK = os.environ.get('GCP_PUBSUB_TOPIC_AFTER_TASK')
GCP_PUBSUB_TOPIC_CRAWL = os.environ.get('GCP_PUBSUB_TOPIC_CRAWL')
GCP_PUBSUB_TOPIC_PREPROCESS = os.environ.get('GCP_PUBSUB_TOPIC_PREPROCESS')
GCP_PUBSUB_TOPIC_TRANSLATE =  os.environ.get('GCP_PUBSUB_TOPIC_TRANSLATE')
GCP_PUBSUB_TOPIC_NLP = os.environ.get('GCP_PUBSUB_TOPIC_NLP')
GCP_PUBSUB_TOPIC_LOAD = os.environ.get('GCP_PUBSUB_TOPIC_LOAD')
GCP_PUBSUB_TOPIC_RESPONSES = os.environ.get('GCP_PUBSUB_TOPIC_RESPONSES')
GCP_PUBSUB_TOPIC_DATA_FLOW = os.environ.get('GCP_PUBSUB_TOPIC_DATA_FLOW')
GCP_PUBSUB_TOPIC_PROGRESS = os.environ.get('GCP_PUBSUB_TOPIC_PROGRESS')

# GCP_PUBSUB_TOPIC_CS_PROGRESS = os.environ.get('GCP_PUBSUB_TOPIC_CS_PROGRESS')
# GCP_PUBSUB_TOPIC_CS_ERROR = os.environ.get('GCP_PUBSUB_TOPIC_CS_ERROR')
GCP_PUBSUB_TOPIC_DISPATCH = os.environ.get('GCP_PUBSUB_TOPIC_DISPATCH')

GCP_PUBSUB_TOPIC_COMPANY_DATASOURCE_PROGRESS = os.environ.get("GCP_PUBSUB_TOPIC_COMPANY_DATASOURCE_PROGRESS")
GCP_PUBSUB_TOPIC_COMPANY_DATASOURCE_ERROR = os.environ.get('GCP_PUBSUB_TOPIC_COMPANY_DATASOURCE_ERROR')
GCP_PUBSUB_TOPIC_INTERNAL_ETL_ERROR = os.environ.get('GCP_PUBSUB_TOPIC_INTERNAL_ETL_ERROR')

# PubSub Subscription
GCP_PUBSUB_SUBSCRIPTION_AFTER_TASK = os.environ.get('GCP_PUBSUB_SUBSCRIPTION_AFTER_TASK')
GCP_PUBSUB_SUBSCRIPTION_PROGRESS = os.environ.get('GCP_PUBSUB_SUBSCRIPTION_PROGRESS')
GCP_PUBSUB_SUBSCRIPTION_DISPATCHER = os.environ.get('GCP_PUBSUB_SUBSCRIPTION_DISPATCHER')
GCP_PUBSUB_SUBSCRIPTION_CRAWLERS = os.environ.get('GCP_PUBSUB_SUBSCRIPTION_CRAWLERS')
GCP_PUBSUB_SUBSCRIPTION_DATA_FLOW = os.environ.get('GCP_PUBSUB_SUBSCRIPTION_DATA_FLOW')
GCP_PUBSUB_SUBSCRIPTION_COMPANY_DATASOURCE_PROGRESS = os.environ.get('GCP_PUBSUB_SUBSCRIPTION_COMPANY_DATASOURCE_PROGRESS')

# Datashake
DATASHAKE_API = os.environ.get('DATASHAKE_API', 'https://app.datashake.com/api/v2')
DATASHAKE_TOKEN = os.environ.get('DATASHAKE_TOKEN')

# Env
ENV = os.environ.get('ENV', 'dev')

# LUMI Proxy
LUMINATI_HTTP_PROXY = os.environ.get('LUMINATI_HTTP_PROXY')
LUMINATI_WEBUNBLOCKER_HTTP_PROXY = os.environ.get('LUMINATI_WEBUNBLOCKER_HTTP_PROXY')

WEBHOOK_API = os.environ.get('WEBHOOK_API')
WEBHOOK_TOKEN = os.environ.get('WEBHOOK_TOKEN')

# Reddit Crawler
REDDIT_CLIENT_ID = os.environ.get("REDDIT_CLIENT_ID", "8zlXlxsFGrW9dQ")
REDDIT_CLIENT_SECRET = os.environ.get("REDDIT_CLIENT_SECRET", "NX207Ak2e2hCfdzrh9qm647sWy3EBQ")

# coresignal
CORESIGNAL_JWT = os.environ.get("CORESIGNAL_JWT")

# MONGODB
MONGODB_DATABASE_URI = os.environ.get("MONGODB_DATABASE_URI")
MONGODB_DATABASE_NAME = os.environ.get("MONGODB_DATABASE_NAME")
MONGODB_DATABASE_ROOT_CA = os.environ.get("MONGODB_DATABASE_ROOT_CA", "/app/certs/root-ca.pem")
MONGODB_DATABASE_KEY_FILE = os.environ.get("MONGODB_DATABASE_KEY_FILE", "/app/certs/dpworker.pem")

MONGODB_VOC_REVIEW_COLLECTION = "voc"
MONGODB_VOE_REVIEW_COLLECTION = "voe"
MONGODB_VOE_OVERVIEW_COLLECTION = "voe_overview"
MONGODB_VOE_JOB_COLLECTION = "voe_job"
MONGODB_VOC_REVIEW_STATS = "voc_review_stats"
MONGODB_VOE_REVIEW_STATS = "voe_review_stats"
MONGODB_CORESIGNAL_STATS = "coresignal_stats"
MONGODB_CORESIGNAL_EMPLOYEES = "coresignal_employees"
MONGODB_CORESIGNAL_CD_MAPPING = "coresignal_company_datasource"

# BigQuery tables
GCP_BQ_TABLE_VOC_CRAWL_STATISTICS = os.environ.get(
    "GCP_BQ_TABLE_VOC_CRAWL_STATISTICS", "leo-etlplatform.dwh.voc_crawl_statistics"
)
GCP_BQ_TABLE_VOE_CRAWL_STATISTICS = os.environ.get(
    "GCP_BQ_TABLE_VOE_CRAWL_STATISTICS", "leo-etlplatform.dwh.voe_crawl_statistics"
)
GCP_BQ_TABLE_HRA_CRAWL_STATISTICS = os.environ.get(
    "GCP_BQ_TABLE_HRA_CRAWL_STATISTICS", "leo-etlplatform.dwh.hra_crawl_statistics"
)
